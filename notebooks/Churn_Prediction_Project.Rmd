---
title: "Churn Prediction Project"
author: "Rener Oliveira"
date: "June 11, 2021"
output: rmdformats::readthedown
bibliography: ../refs.bib
---

```{r setup, include=FALSE,message=FALSE,warning=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Data description

The dataset was released by [CrowdAnalytix Community](https://www.crowdanalytix.com/contests/why-customer-churn/) as part of their churn prediction 2012 challenge. It has 3333 customer entries with 20 features each, from a telecom company, which the real name was anonymized. We got a copy from [Kaggle](https://www.kaggle.com/mnassrib/telecom-churn-datasets) which was already divided  80% for the training set and 20% for test.

```{r,message=FALSE,warning=FALSE}
library(dplyr)
library(ggplot2)
library(reshape2)
library(gridExtra)
library(scales)
library(performanceEstimation)
library(class)
library(PRROC)
source("../functions.R") #Auxiliar functions script
```


```{r}
train <- read.csv("../data/churn-bigml-80.csv")
test <- read.csv("../data/churn-bigml-20.csv")
str(train)
```

The column names are self-explanatory, *eve* stands for *evenings*, *intl* for *international* and *vmail* for *voice mails*. We're gonna transform `International.plan`,`Voice.mail.plan` and `Churn` columns into binary variables, and mutate the `State` column into regions. We don't need to do any further manipulation since the data is already well treated and there is no missing data.


```{r}
train <- train %>% mutate(Churn=ifelse(Churn=="True",1,0),
                          International.plan=ifelse(International.plan=="Yes",1,0),
                          Voice.mail.plan=ifelse(Voice.mail.plan=="Yes",1,0))

test <- test %>% mutate(Churn=ifelse(Churn=="True",1,0),
                          International.plan=ifelse(International.plan=="Yes",1,0),
                          Voice.mail.plan=ifelse(Voice.mail.plan=="Yes",1,0))

data(state) #load buit-in state dataset
regions <- data.frame(cbind(state.abb,as.character(state.region)))
names(regions) <- c("State","Region")

train <- train %>% mutate(State=ifelse(State=="DC","VA",as.character(State))) %>%
  left_join(by="State",y=regions) %>% select(-State)
test <- test %>% mutate(State=ifelse(State=="DC","VA",as.character(State))) %>%
  left_join(by="State",y=regions) %>% select(-State)

sum(is.na(train))+sum(is.na(test))
```

# Visualizations

First of all let's see the proportion of churners in our dataset.

```{r}
train_churn <- c(sum(train$Churn)/nrow(train),1-sum(train$Churn)/nrow(train))
test_churn <- c(sum(test$Churn)/nrow(test),1-sum(test$Churn)/nrow(test))
colors <- c('#FFEB6E','#32FF6E')
par(mfrow=c(1,2))
pie(train_churn,label = round(100*train_churn,1),main="Train",col = colors)
pie(test_churn,label = round(100*test_churn,1),main="Test",col = colors)
legend("bottomleft", c("% Churners","% Non-churners"), cex = 0.8,fill = colors)
```


Both splits have around 14.4% of churners, this proportion can lead to class imbalance bias, and we may need to deal with it with data-level solutions such as resampling techniques.

Let`s analyse continuous variable correlation:
```{r}
# Reference: http://www.sthda.com/english/wiki/ggplot2-quick-correlation-matrix-heatmap-r-software-and-data-visualization
corr <- round(cor(train[,-c(3,4,19,20)]),2)
corr[lower.tri(corr)] <- NA
corr <- melt(corr,na.rm=T)
ggplot(data=corr,aes(x=Var2,y=Var1,fill = value)) + 
  geom_tile(color="white") + 
  scale_fill_gradient2(mid="#fddbc7",high="red",low="white",
                       space="Lab",name = "Correlation\n") + 
  labs(x="",y="") + theme_minimal() + 
 theme(axis.text.x = element_text(angle = 40, vjust = 1, hjust = 1))+
 coord_fixed() + 
  geom_text(aes(Var2, Var1, label = value), color = "black", size = 2.1)
```

As we can see above, the vast majority of the features are uncorrelated. But the pairs like total minutes/total charge are perfectly correlated, which makes sense if users are charged by minutes used. We choose to remove the charge variables to avoid multicollinearity.
```{r}
train <- train %>% select(-Total.day.charge,-Total.eve.charge,
                          -Total.night.charge,-Total.intl.charge)
test <- test %>% select(-Total.day.charge,-Total.eve.charge,
                          -Total.night.charge,-Total.intl.charge)
# write.csv(train,"../data/train_cleaned.csv",row.names=FALSE)
# write.csv(test,"../data/test_cleaned.csv",row.names=FALSE)
names(train)
```

Below we can see that churners make more calls to customer services than non-churners.

```{r,fig.height=3.5,fig.width=7}
plot_var("Customer.service.calls",nbins=10)
```

Although Northeast and South regions have more churners, the churn percentage in all regions is around 14% which was the % in the train set as a whole.

```{r,fig.height=3,fig.width=6}
train %>% group_by(Region) %>% 
  summarize(churn_perc=sum(Churn/n())) %>%
  ggplot(aes(x=Region,y=churn_perc)) +
  geom_col() +
  scale_y_continuous(labels = scales::percent) +
  labs(title = "Churn % by Region")
```

Among churners, we have fewer customers with voice mail plan (~16.75%) comparing with non-churners subscribed to this plan (~29.32%).

```{r,fig.height=5,fig.width=5}
train  %>% mutate(Churn=as.factor(Churn)) %>% 
  group_by(Churn) %>% 
  summarise(has_vmail_plan=sum(Voice.mail.plan)/n()) %>%  ggplot() + geom_bar(aes(x=Churn,y=has_vmail_plan,fill=Churn),stat="identity") +
  scale_y_continuous(labels = scales::percent) + 
  labs(title="% of customers with voicemail plan",y="") + theme_minimal()
```

On the other hand, we have much more churners with an international plan, comparing with non-churners. A possible explanation would be that international plan subscribers are finding better offers in this service with competitors. 

```{r,fig.height=5,fig.width=5}
train  %>% mutate(Churn=as.factor(Churn)) %>% 
  group_by(Churn) %>% 
  summarise(has_intl_plan=sum(International.plan)/n()) %>%  ggplot() + geom_bar(aes(x=Churn,y=has_intl_plan,fill=Churn),stat="identity") +
  scale_y_continuous(labels = scales::percent) + 
  labs(title="% of customers with International plan",y="") + theme_minimal()
```

```{r}
plot_var("Total.day.minutes")
```

# Evaluation Metrics

There are a number of metrics to evaluate classification algorithms, we list some that we're gonna use, but in churn prediction problem we'll have to pay special atention to specific ones. (TP = True Positive, TN = True Negative, FP = False Positive, FN = False Negative, N = total number of observations).

- Accuracy: (TP+TN)/N
- Recall: TP/(TP+FN)
- AUC: Area under ROC curve
- Lift

[@class_imbalance] If the model yields probabilities, we sort the test predictions by these probabilities in a descending order, then we define the lift as the ratio between the percentage of positive entries in the top 10\% lines ($\beta_{10\%}$), and the percentage of churners (positives) in the entire test set ($\beta_0$). 

$$\text{top decile lift} = \dfrac{\beta_{10\%}}{\beta_0}$$
That's a widely used performance metric for this kind of problem. A top-decile lift of 2 means that the model classifies two times more churners in the top 10% group than a random classifier. We'll devote special attention to recall and top-decile lift, 'cause of the imbalance problem. If a model predicts 0 to every test observation, it would be ~85% accurate, but recall would be zero, and lift undefined.

# Resampling methods

Our reference [@class_imbalance] presents a lot of methods to deal with class imbalance, from data-level solutions to adapted algorithms. We'll focus our tests on resampling our training set to create a rebalanced new one.

- (ROS) Random Oversampling: randomly replicates churners instances.
- (RUS) Random Undersampling: randomly eliminates the non-churners instances
- (SMOTE) Synthetic minority oversampling technique [@smote]

Smote oversamples the minority class by creating random linear interpolations between a given sample and its nearest neighbors.

See ROS and RUS implementation in [functions.R](https://github.com/reneroliveira/Churn_Prediction_Project/blob/main/functions.R). Smote is implemented on `performanceEstimation` library.

# Classification Methods

## Logistic Regression
```{r}
logistic_reg <- glm(Churn ~ ., data = train, family = "binomial")
summary(logistic_reg)
```

The ROC curve:
```{r,fig.height=4,fig.width=5.5}
roc_logistic <- roc.curve(scores.class0 = logit2prob(predict(logistic_reg,newdata = test)),weights.class0=test$Churn,curve=TRUE)
plot(roc_logistic,main = "ROC Curve - Logistic Regression") 
```

By changing the 10% percentile from the lift definition we can also generate a lift curve, but for model comparison, we'll use the decile version.

```{r}
quantiles <- seq(0.1,1,length.out = 10)
lifts <- sapply(quantiles,function(x){return(lift(predict(logistic_reg,newdata =test),test$Churn,quantile=x))})
plot(quantiles,lifts,type='b',main="Lift Curve")
```

```{r}
set.seed(123)

train <- train %>% mutate(Churn = as.factor(Churn))
Majority <- sum(train$Churn==0)
minority <- nrow(train)-Majority
resamples <- list("Original" = train,
                  "ROS" = ROS(train,"Churn"),
                  "RUS" = RUS(train,"Churn"),
                  "SMOTE" =  smote(Churn ~ ., train, perc.over = Majority/minority,perc.under=1))

#save(resamples,file="../data/resamples.rda")


for(i in c("Original","ROS","RUS","SMOTE")){
  data <-  resamples[i][[1]]
  model <- glm(Churn ~ ., data = data, family = "binomial")
  scores <- predict(model,newdata =test)
  ypred <- logit2prob(scores)>0.5
  print(i)
  print(evaluate(ypred,test$Churn,scores))
}
```

## K-Nearest-Neighbors

Let's compare KNN performance between the resamples generated before. We'll perform cross-validation to select k, using the undersampled dataset.

```{r}
# for(i in c("Original","ROS","RUS","SMOTE")){
#   data <-  resamples[i][[1]]
#   model <- glm(Churn ~ ., data = data, family = "binomial")
#   scores <- predict(model,newdata =test)
#   ypred <- logit2prob(scores)>0.5
#   print(i)
#   print(evaluate(ypred,test$Churn,model,test,scores))
# }
t2 <- dummy_cols(resamples["SMOTE"][[1]],select_columns = "Region") %>% select(-Region,-`Region_North Central`)
tes2 <- dummy_cols(test,select_columns = "Region") %>% select(-Region,-`Region_North Central`)
churn.knn = knn(train = t2[,-15] , test = tes2[,-15], cl = t2$Churn, k=5, prob=TRUE)
knn.probs = attr(churn.knn,"prob")

evaluate(churn.knn,tes2$Churn,knn.probs)


n = nrow(resamples["RUS"][[1]])
n_rep = 5
k_values = c(2:15)

lift_cv = matrix(NA, n_rep, length(k_values))

for(i_n_rep in 1:n_rep){
  i_treino = sample(1:n, n/2)
  i_teste = seq(1:n)[-i_treino]
  for(i_k in 1:length(k_values)){
    reg_auto_poly = lm(mpg ~ poly(horsepower, i_degree), Auto[i_treino,])
    pred_reg = predict(reg_auto_poly, Auto[i_teste,])
    mse[i_n_rep, i_degree] = mean((pred_reg- Auto[i_teste,"mpg"])^2)
  }
}

```

# References
